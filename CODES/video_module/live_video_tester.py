#!/usr/bin/env python3
"""
ğŸ¬ LIVE VIDEO TESTER - YOLOv8x Real-Time Detection
ğŸ¯ KAMERA 2 iÃ§in koordinat tabanlÄ± test sistemi

ğŸ“‹ Features:
- YOLOv8x model ile detection
- Frame-by-frame koordinat analizi
- OUTPUT klasÃ¶rÃ¼ne organize kayÄ±t
- Real-time performance tracking
- Comprehensive logging

ğŸ‘¥ Team: FURKAN & NISA
ğŸ“… Date: 31 Temmuz 2025
"""

import cv2
import os
import sys
from datetime import datetime
import json
import csv
from pathlib import Path
import time
import numpy as np

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from ultralytics import YOLO
import logging

def setup_logger(name, log_file):
    """Simple logger setup"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # File handler
    fh = logging.FileHandler(log_file)
    fh.setLevel(logging.INFO)
    
    # Console handler
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    
    # Formatter
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    
    logger.addHandler(fh)
    logger.addHandler(ch)
    
    return logger

class LiveVideoTester:
    def __init__(self, video_path, model_path="yolov8x.pt"):
        """
        ğŸ¯ Live Video Tester Initialization
        
        Args:
            video_path (str): Input video dosya yolu
            model_path (str): YOLO model dosya yolu
        """
        self.video_path = video_path
        self.model_path = model_path
        
        # Video dosya ismini al
        self.video_name = Path(video_path).stem
        
        # Timestamp oluÅŸtur
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Output klasÃ¶rÃ¼ oluÅŸtur
        self.output_dir = self._create_output_directory()
        
        # Logger setup
        self.logger = setup_logger(
            name="live_tester",
            log_file=os.path.join(self.output_dir, "detection_log.txt")
        )
        
        # Performance tracking
        self.frame_count = 0
        self.detection_count = 0
        self.total_time = 0
        
        # Detection data storage
        self.detection_data = []
        
        self.logger.info(f"ğŸš€ Live Video Tester baÅŸlatÄ±ldÄ±")
        self.logger.info(f"ğŸ“¹ Video: {self.video_name}")
        self.logger.info(f"ğŸ¤– Model: {self.model_path}")
        self.logger.info(f"ğŸ“‚ Output: {self.output_dir}")

    def _create_output_directory(self):
        """ğŸ“ OUTPUT klasÃ¶rÃ¼ oluÅŸtur"""
        base_output = Path(__file__).parent.parent.parent / "OUTPUT"
        base_output.mkdir(exist_ok=True)
        
        folder_name = f"LIVE_TEST_yolov8x_{self.video_name}_{self.timestamp}"
        output_dir = base_output / folder_name
        output_dir.mkdir(exist_ok=True)
        
        return str(output_dir)

    def load_model(self):
        """ğŸ¤– YOLO model yÃ¼kle"""
        try:
            models_dir = Path(__file__).parent.parent.parent / "MODELS"
            model_full_path = models_dir / self.model_path
            
            if not model_full_path.exists():
                # EÄŸer MODELS klasÃ¶rÃ¼nde yoksa, default model kullan
                self.logger.warning(f"âš ï¸ Model bulunamadÄ±: {model_full_path}")
                self.logger.info(f"ğŸ”„ Default YOLOv8x model kullanÄ±lÄ±yor...")
                self.model = YOLO('yolov8x.pt')
            else:
                self.logger.info(f"ğŸ“¥ Model yÃ¼kleniyor: {model_full_path}")
                self.model = YOLO(str(model_full_path))
            
            self.logger.info(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: {self.model_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            return False

    def detect_objects(self, frame, frame_number, timestamp):
        """
        ğŸ¯ Tek frame'de object detection yap
        
        Args:
            frame: OpenCV frame
            frame_number: Frame numarasÄ±
            timestamp: Frame timestamp
        
        Returns:
            tuple: (annotated_frame, detections_list)
        """
        try:
            # YOLO detection
            start_time = time.time()
            results = self.model(frame, verbose=False)
            detection_time = time.time() - start_time
            
            detections = []
            annotated_frame = frame.copy()
            
            # Results process et
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for i, box in enumerate(boxes):
                        # KoordinatlarÄ± al
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # Class name al
                        class_name = self.model.names[class_id]
                        
                        # Center point hesapla
                        center_x = int((x1 + x2) / 2)
                        center_y = int((y1 + y2) / 2)
                        
                        # Detection data kaydet
                        detection_info = {
                            'frame_number': frame_number,
                            'timestamp': timestamp,
                            'detection_id': f"{frame_number}_{i}",
                            'class_id': class_id,
                            'class_name': class_name,
                            'confidence': float(confidence),
                            'bbox': {
                                'x1': float(x1), 'y1': float(y1),
                                'x2': float(x2), 'y2': float(y2)
                            },
                            'center': {'x': center_x, 'y': center_y},
                            'detection_time': detection_time
                        }
                        detections.append(detection_info)
                        
                        # Sadece 'person' sÄ±nÄ±fÄ±nÄ± iÅŸle (class_id = 0)
                        if class_id == 0 and confidence > 0.3:
                            self.detection_count += 1
                            
                            # Bounding box Ã§iz
                            color = self._get_color_for_confidence(confidence)
                            cv2.rectangle(annotated_frame, 
                                        (int(x1), int(y1)), (int(x2), int(y2)), 
                                        color, 2)
                            
                            # Center point Ã§iz
                            cv2.circle(annotated_frame, (center_x, center_y), 5, color, -1)
                            
                            # Text bilgileri
                            label = f"Person {confidence:.2f}"
                            coord_text = f"({center_x},{center_y})"
                            
                            # Label background
                            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                            cv2.rectangle(annotated_frame, 
                                        (int(x1), int(y1-25)), (int(x1+label_w), int(y1)), 
                                        color, -1)
                            
                            # Label text
                            cv2.putText(annotated_frame, label,
                                      (int(x1), int(y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 
                                      0.6, (255, 255, 255), 2)
                            
                            # Koordinat text
                            cv2.putText(annotated_frame, coord_text,
                                      (int(x1), int(y2+20)), cv2.FONT_HERSHEY_SIMPLEX, 
                                      0.5, color, 1)
            
            return annotated_frame, detections
            
        except Exception as e:
            self.logger.error(f"âŒ Detection hatasÄ± frame {frame_number}: {e}")
            return frame, []

    def _get_color_for_confidence(self, confidence):
        """ğŸ¨ Confidence'a gÃ¶re renk belirle"""
        if confidence > 0.8:
            return (0, 255, 0)    # YeÅŸil - yÃ¼ksek confidence
        elif confidence > 0.6:
            return (0, 255, 255)  # SarÄ± - orta confidence
        else:
            return (0, 165, 255)  # Turuncu - dÃ¼ÅŸÃ¼k confidence

    def process_video(self):
        """ğŸ¬ Video'yu frame-by-frame iÅŸle"""
        self.logger.info("ğŸ¬ Video iÅŸleme baÅŸladÄ±...")
        
        # Video aÃ§
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            self.logger.error(f"âŒ Video aÃ§Ä±lamadÄ±: {self.video_path}")
            return False
        
        # Video properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        self.logger.info(f"ğŸ“Š Video Ã¶zellikleri: {frame_width}x{frame_height}, {fps} FPS, {total_frames} frame")
        
        # Output video writer
        output_video_path = os.path.join(self.output_dir, "live_test_result.mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))
        
        # CSV dosyasÄ± iÃ§in baÅŸlÄ±k
        csv_path = os.path.join(self.output_dir, "coordinates_log.csv")
        csv_headers = ['frame_number', 'timestamp', 'detection_id', 'class_name', 
                      'confidence', 'x1', 'y1', 'x2', 'y2', 'center_x', 'center_y', 'detection_time']
        
        start_time = time.time()
        
        # ğŸ¯ 1 DAKÄ°KALIK TEST: 14 FPS * 60 saniye = 840 frame
        max_frames_1min = 840
        
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=csv_headers)
                writer.writeheader()
                
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # ğŸ¯ 1 dakika limit
                    if self.frame_count >= max_frames_1min:
                        self.logger.info(f"ğŸ¯ 1 dakikalÄ±k test tamamlandÄ±! ({max_frames_1min} frame)")
                        break
                    
                    self.frame_count += 1
                    frame_timestamp = self.frame_count / fps
                    
                    # Detection yap
                    annotated_frame, detections = self.detect_objects(
                        frame, self.frame_count, frame_timestamp
                    )
                    
                    # Frame info overlay
                    self._add_frame_info(annotated_frame, self.frame_count, 
                                       len(detections), frame_timestamp)
                    
                    # Video'ya yaz
                    out.write(annotated_frame)
                    
                    # CSV'ye detection'larÄ± yaz
                    for detection in detections:
                        if detection['class_name'] == 'person':
                            csv_row = {
                                'frame_number': detection['frame_number'],
                                'timestamp': f"{detection['timestamp']:.2f}",
                                'detection_id': detection['detection_id'],
                                'class_name': detection['class_name'],
                                'confidence': f"{detection['confidence']:.3f}",
                                'x1': f"{detection['bbox']['x1']:.1f}",
                                'y1': f"{detection['bbox']['y1']:.1f}",
                                'x2': f"{detection['bbox']['x2']:.1f}",
                                'y2': f"{detection['bbox']['y2']:.1f}",
                                'center_x': detection['center']['x'],
                                'center_y': detection['center']['y'],
                                'detection_time': f"{detection['detection_time']:.4f}"
                            }
                            writer.writerow(csv_row)
                    
                    # Detection data'yÄ± kaydet
                    self.detection_data.extend(detections)
                    
                    # Progress log (her 50 frame'de bir)
                    if self.frame_count % 50 == 0:
                        progress = (self.frame_count / total_frames) * 100
                        self.logger.info(f"ğŸ“ˆ Ä°lerleme: {self.frame_count}/{total_frames} ({progress:.1f}%)")
                    
        except Exception as e:
            self.logger.error(f"âŒ Video iÅŸleme hatasÄ±: {e}")
            return False
        
        finally:
            cap.release()
            out.release()
        
        self.total_time = time.time() - start_time
        self.logger.info(f"âœ… Video iÅŸleme tamamlandÄ±!")
        
        return True

    def _add_frame_info(self, frame, frame_number, detection_count, timestamp):
        """ğŸ“Š Frame'e bilgi overlay'i ekle"""
        # Background rectangle
        cv2.rectangle(frame, (10, 10), (400, 80), (0, 0, 0), -1)
        
        # Frame info
        frame_text = f"Frame: {frame_number}"
        time_text = f"Time: {timestamp:.2f}s"
        detection_text = f"Detections: {detection_count}"
        
        cv2.putText(frame, frame_text, (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, time_text, (20, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, detection_text, (20, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    def save_performance_metrics(self):
        """ğŸ“ˆ Performance metrics'leri kaydet"""
        if self.total_time == 0:
            return
        
        avg_fps = self.frame_count / self.total_time
        avg_detection_time = self.total_time / self.frame_count if self.frame_count > 0 else 0
        detection_density = self.detection_count / self.frame_count if self.frame_count > 0 else 0
        
        metrics = {
            'test_info': {
                'video_name': self.video_name,
                'model_used': self.model_path,
                'test_timestamp': self.timestamp,
                'total_processing_time': round(self.total_time, 2)
            },
            'frame_stats': {
                'total_frames': self.frame_count,
                'total_detections': self.detection_count,
                'detection_density': round(detection_density, 3)
            },
            'performance': {
                'average_fps': round(avg_fps, 2),
                'average_detection_time_per_frame': round(avg_detection_time, 4),
                'real_time_capable': avg_fps >= 25
            },
            'quality_metrics': {
                'frames_with_detections': len([d for d in self.detection_data if d['class_name'] == 'person']),
                'average_confidence': round(np.mean([d['confidence'] for d in self.detection_data if d['class_name'] == 'person']), 3) if self.detection_data else 0,
                'high_confidence_detections': len([d for d in self.detection_data if d['class_name'] == 'person' and d['confidence'] > 0.8])
            }
        }
        
        # JSON olarak kaydet
        metrics_path = os.path.join(self.output_dir, "performance_metrics.json")
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        # Log'a yazdÄ±r
        self.logger.info("ğŸ“Š PERFORMANCE METRICS")
        self.logger.info(f"â±ï¸  Total Time: {metrics['test_info']['total_processing_time']}s")
        self.logger.info(f"ğŸ¬ Processed Frames: {metrics['frame_stats']['total_frames']}")
        self.logger.info(f"ğŸ¯ Total Detections: {metrics['frame_stats']['total_detections']}")
        self.logger.info(f"ğŸš€ Average FPS: {metrics['performance']['average_fps']}")
        self.logger.info(f"ğŸ“ˆ Detection Density: {metrics['frame_stats']['detection_density']}")
        self.logger.info(f"ğŸ¯ Average Confidence: {metrics['quality_metrics']['average_confidence']}")
        
        return metrics

def main():
    """ğŸš€ Main execution function"""
    print("ğŸ¬ LIVE VIDEO TESTER - YOLOv8x Detection")
    print("=" * 50)
    
    # Video path belirle
    data_dir = Path(__file__).parent.parent.parent / "0_DATA"
    video_path = data_dir / "kamera2.mov"
    
    if not video_path.exists():
        print(f"âŒ Video bulunamadÄ±: {video_path}")
        print(f"ğŸ“‚ DATA klasÃ¶rÃ¼ iÃ§eriÄŸi:")
        for file in data_dir.glob("*"):
            print(f"   - {file.name}")
        return
    
    print(f"ğŸ“¹ Test Video: {video_path.name}")
    print(f"ğŸ¤– Model: YOLOv8x")
    print("ğŸš€ Test baÅŸlatÄ±lÄ±yor...\n")
    
    # Tester oluÅŸtur ve Ã§alÄ±ÅŸtÄ±r
    tester = LiveVideoTester(str(video_path), "yolov8x.pt")
    
    # Model yÃ¼kle
    if not tester.load_model():
        print("âŒ Model yÃ¼klenemedi!")
        return
    
    # Video iÅŸle
    if tester.process_video():
        print("\nâœ… Video iÅŸleme baÅŸarÄ±lÄ±!")
        
        # Performance metrics kaydet
        metrics = tester.save_performance_metrics()
        
        print(f"\nğŸ“‚ Output KlasÃ¶rÃ¼: {tester.output_dir}")
        print("ğŸ“ OluÅŸturulan dosyalar:")
        print("   ğŸ“¹ live_test_result.mp4")
        print("   ğŸ“Š coordinates_log.csv") 
        print("   ğŸ“ detection_log.txt")
        print("   ğŸ“ˆ performance_metrics.json")
        
        print(f"\nğŸ¯ SONUÃ‡LAR:")
        print(f"   â±ï¸  Ä°ÅŸlem SÃ¼resi: {metrics['test_info']['total_processing_time']}s")
        print(f"   ğŸ¬ Ä°ÅŸlenen Frame: {metrics['frame_stats']['total_frames']}")
        print(f"   ğŸ¯ Tespit SayÄ±sÄ±: {metrics['frame_stats']['total_detections']}")
        print(f"   ğŸš€ Ortalama FPS: {metrics['performance']['average_fps']}")
        
    else:
        print("âŒ Video iÅŸleme baÅŸarÄ±sÄ±z!")

if __name__ == "__main__":
    main()