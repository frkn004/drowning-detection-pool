#!/usr/bin/env python3
"""
ğŸ“Š DATASET PREPARATION SCRIPT
============================
5_TÄ°CKET_DATA klasÃ¶rÃ¼nden eÄŸitim dataset'ini hazÄ±rlar
"""

import os
import shutil
import random
from pathlib import Path
from collections import defaultdict, Counter

class DatasetPreparer:
    def __init__(self, source_dir="5_TÄ°CKET_DATA", target_dir="8_TRAINING/dataset"):
        """
        Dataset Preparer
        
        Args:
            source_dir: Kaynak etiketlenmiÅŸ data klasÃ¶rÃ¼
            target_dir: Hedef dataset klasÃ¶rÃ¼
        """
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        
        # Kaynak klasÃ¶rler
        self.frames_dir = self.source_dir / "01_frames"
        self.labels_dir = self.source_dir / "02_labels"
        self.classes_file = self.source_dir / "classes.txt"
        
        # Hedef klasÃ¶rler
        self.train_images = self.target_dir / "images" / "train"
        self.train_labels = self.target_dir / "labels" / "train"
        self.val_images = self.target_dir / "images" / "val"
        self.val_labels = self.target_dir / "labels" / "val"
        
        self.classes = self.load_classes()
        
    def load_classes(self):
        """SÄ±nÄ±flarÄ± yÃ¼kle"""
        if self.classes_file.exists():
            with open(self.classes_file, 'r') as f:
                return [line.strip() for line in f.readlines()]
        else:
            # Default classes
            return ["person_swimming", "person_drowning", "person_poolside", "pool_equipment"]
    
    def analyze_dataset(self):
        """Dataset analizini yap"""
        print("ğŸ” Dataset analizi...")
        
        # Frame sayÄ±sÄ±
        if self.frames_dir.exists():
            frames = list(self.frames_dir.glob("*.jpg"))
            print(f"ğŸ“¸ Toplam frame: {len(frames)}")
        else:
            print(f"âŒ Frame klasÃ¶rÃ¼ bulunamadÄ±: {self.frames_dir}")
            return False
            
        # Label sayÄ±sÄ± ve daÄŸÄ±lÄ±mÄ±
        if self.labels_dir.exists():
            labels = list(self.labels_dir.glob("*.txt"))
            print(f"ğŸ·ï¸ Toplam label dosyasÄ±: {len(labels)}")
            
            # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± analiz et
            class_counts = Counter()
            total_annotations = 0
            
            for label_file in labels:
                with open(label_file, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            if 0 <= class_id < len(self.classes):
                                class_counts[self.classes[class_id]] += 1
                                total_annotations += 1
            
            print(f"ğŸ“Š Toplam annotation: {total_annotations}")
            print("ğŸ“ˆ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
            for class_name in self.classes:
                count = class_counts.get(class_name, 0)
                percentage = (count / total_annotations * 100) if total_annotations > 0 else 0
                print(f"   {class_name}: {count} ({percentage:.1f}%)")
                
        else:
            print(f"âŒ Label klasÃ¶rÃ¼ bulunamadÄ±: {self.labels_dir}")
            return False
            
        return True
    
    def create_directories(self):
        """Hedef klasÃ¶rleri oluÅŸtur"""
        print("ğŸ“ KlasÃ¶r yapÄ±sÄ± oluÅŸturuluyor...")
        
        directories = [
            self.train_images, self.train_labels,
            self.val_images, self.val_labels
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            print(f"   âœ… {directory}")
    
    def get_valid_pairs(self):
        """GeÃ§erli frame-label Ã§iftlerini bul"""
        print("ğŸ” GeÃ§erli frame-label Ã§iftleri bulunuyor...")
        
        frames = set(f.stem for f in self.frames_dir.glob("*.jpg"))
        labels = set(f.stem for f in self.labels_dir.glob("*.txt"))
        
        # Ortak dosyalar
        valid_pairs = frames.intersection(labels)
        
        print(f"ğŸ“¸ Frame dosyalarÄ±: {len(frames)}")
        print(f"ğŸ·ï¸ Label dosyalarÄ±: {len(labels)}")
        print(f"âœ… GeÃ§erli Ã§iftler: {len(valid_pairs)}")
        
        if len(valid_pairs) == 0:
            print("âŒ GeÃ§erli Ã§ift bulunamadÄ±!")
            return []
            
        return list(valid_pairs)
    
    def split_dataset(self, valid_pairs, val_split=0.2, phase="all"):
        """
        Dataset'i train/val olarak bÃ¶l
        
        Args:
            valid_pairs: GeÃ§erli dosya Ã§iftleri
            val_split: Validation oranÄ± (0.2 = %20)
            phase: Hangi phase (phase1=200, phase2=500, etc.)
        """
        print(f"ğŸ“Š Dataset bÃ¶lÃ¼nÃ¼yor... (val_split: {val_split})")
        
        # Phase'e gÃ¶re dosya sayÄ±sÄ±nÄ± sÄ±nÄ±rla
        phase_limits = {
            "phase1": 200,
            "phase2": 500, 
            "phase3": 1000,
            "phase4": 1500,
            "all": len(valid_pairs)
        }
        
        limit = phase_limits.get(phase, len(valid_pairs))
        if len(valid_pairs) > limit:
            # En kaliteli frame'leri seÃ§ (dosya boyutuna gÃ¶re)
            frame_sizes = []
            for pair in valid_pairs:
                frame_path = self.frames_dir / f"{pair}.jpg"
                if frame_path.exists():
                    size = frame_path.stat().st_size
                    frame_sizes.append((pair, size))
            
            # BÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe sÄ±rala (daha kaliteli)
            frame_sizes.sort(key=lambda x: x[1], reverse=True)
            valid_pairs = [pair for pair, _ in frame_sizes[:limit]]
            print(f"ğŸ¯ {phase} iÃ§in en kaliteli {limit} frame seÃ§ildi")
        
        # KarÄ±ÅŸtÄ±r
        random.shuffle(valid_pairs)
        
        # Train/val split
        val_size = int(len(valid_pairs) * val_split)
        train_pairs = valid_pairs[val_size:]
        val_pairs = valid_pairs[:val_size]
        
        print(f"ğŸš‚ Train set: {len(train_pairs)} dosya")
        print(f"âœ… Validation set: {len(val_pairs)} dosya")
        
        return train_pairs, val_pairs
    
    def copy_files(self, pairs, target_images_dir, target_labels_dir, set_name):
        """DosyalarÄ± hedef klasÃ¶re kopyala"""
        print(f"ğŸ“‹ {set_name} dosyalarÄ± kopyalanÄ±yor...")
        
        success_count = 0
        
        for pair in pairs:
            # Frame kopyala
            source_frame = self.frames_dir / f"{pair}.jpg"
            target_frame = target_images_dir / f"{pair}.jpg"
            
            # Label kopyala
            source_label = self.labels_dir / f"{pair}.txt"
            target_label = target_labels_dir / f"{pair}.txt"
            
            try:
                shutil.copy2(source_frame, target_frame)
                shutil.copy2(source_label, target_label)
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ Hata {pair}: {e}")
        
        print(f"âœ… {set_name}: {success_count}/{len(pairs)} dosya kopyalandÄ±")
        return success_count
    
    def prepare_dataset(self, phase="phase1", val_split=0.2):
        """
        Dataset'i hazÄ±rla
        
        Args:
            phase: EÄŸitim fazÄ±
            val_split: Validation split oranÄ±
        """
        print(f"ğŸš€ DATASET HAZIRLIÄI - {phase.upper()}")
        print("=" * 50)
        
        # Analiz
        if not self.analyze_dataset():
            return False
        
        # KlasÃ¶rler oluÅŸtur
        self.create_directories()
        
        # GeÃ§erli Ã§iftleri bul
        valid_pairs = self.get_valid_pairs()
        if not valid_pairs:
            return False
        
        # Train/val split
        train_pairs, val_pairs = self.split_dataset(valid_pairs, val_split, phase)
        
        # DosyalarÄ± kopyala
        train_success = self.copy_files(train_pairs, self.train_images, self.train_labels, "TRAIN")
        val_success = self.copy_files(val_pairs, self.val_images, self.val_labels, "VALIDATION")
        
        # Classes dosyasÄ±nÄ± kopyala
        target_classes = self.target_dir / "classes.txt"
        shutil.copy2(self.classes_file, target_classes)
        print(f"ğŸ“‹ Classes kopyalandÄ±: {target_classes}")
        
        print(f"\nâœ… DATASET HAZIRLIÄI TAMAMLANDI!")
        print(f"ğŸ“Š Train: {train_success} dosya")
        print(f"ğŸ“Š Validation: {val_success} dosya")
        print(f"ğŸ“ Hedef klasÃ¶r: {self.target_dir}")
        
        return True

def main():
    """Ana dataset hazÄ±rlama fonksiyonu"""
    print("ğŸ“Š DROWNING DETECTION DATASET PREPARER")
    print("======================================")
    
    phases = {
        '1': 'phase1',  # 200 frame
        '2': 'phase2',  # 500 frame
        '3': 'phase3',  # 1000 frame
        '4': 'phase4',  # 1500 frame
        'a': 'all'      # TÃ¼m frameler
    }
    
    print("ğŸ“Š Dataset hazÄ±rlama seÃ§enekleri:")
    print("   1. Phase 1: Mini Dataset (200 frame)")
    print("   2. Phase 2: Extended Dataset (500 frame)")
    print("   3. Phase 3: Production Dataset (1000 frame)")
    print("   4. Phase 4: Final Dataset (1500 frame)")
    print("   a. All: TÃ¼m Dataset")
    
    try:
        choice = input("\nHangi dataset'i hazÄ±rlamak istiyorsunuz? (1-4/a): ").strip()
        phase = phases.get(choice)
        
        if not phase:
            print("âŒ GeÃ§ersiz seÃ§im!")
            return
        
        val_split = float(input("Validation split oranÄ± (0.2 = %20): ") or "0.2")
        
        # Dataset preparer oluÅŸtur
        preparer = DatasetPreparer()
        success = preparer.prepare_dataset(phase, val_split)
        
        if success:
            print(f"\nğŸ‰ {phase.upper()} dataset hazÄ±rlÄ±ÄŸÄ± baÅŸarÄ±lÄ±!")
        else:
            print(f"\nâŒ {phase.upper()} dataset hazÄ±rlÄ±ÄŸÄ± baÅŸarÄ±sÄ±z!")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")

if __name__ == "__main__":
    main()